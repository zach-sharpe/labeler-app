# HDF5 Chunked Waveform Data Format

This document describes the structure and format of HDF5 files generated by the `save_chunked_data_to_hdf5()` function in `segment_waveform_data.py`.

## Overview

The HDF5 files store preprocessed waveform data that has been:
1. Resampled to a target frequency (e.g., 125 Hz or 200 Hz)
2. Filtered to remove bad data (keeping only good quality data)
3. Split into fixed-size chunks with configurable overlap

This format is optimized for machine learning applications and efficient data access.

## File Structure

The HDF5 file is organized into four main groups:

```
/
├── signals/          # Chunked waveform signal arrays
│   ├── time         # Time values (n_chunks, chunk_size)
│   ├── abp          # Arterial Blood Pressure (n_chunks, chunk_size)
│   ├── ecg          # Electrocardiogram [if present]
│   └── ...          # Other signals from the original data
│
├── labels/           # Chunk-level labels
│   └── cpr_label        # CPR status per chunk (n_chunks,) [0=non-CPR, 1=CPR]
│
├── annotations/      # Review annotations (time ranges in seconds)
│   ├── pause_times      # Pause events (n_pause, 2) [start, stop]
│   ├── rosc_times       # Any ROSC events (n_rosc, 2) [start, stop]
│   └── bad_data_times   # Bad Data events (n_bad, 2) [start, stop]
│
└── metadata/         # Processing parameters and patient info
    ├── patient_id       # Patient identifier (string)
    ├── chunk_size       # Samples per chunk (int)
    ├── skip_size        # Samples between chunk starts (int)
    ├── sampling_rate    # Sampling frequency in Hz (float)
    ├── drop_incomplete  # Whether incomplete chunks were dropped (bool)
    └── ...              # Other custom parameters
```

## Group Descriptions

### `/signals/` Group

Contains all waveform signal arrays in chunked format.

**Dataset Structure:**
- **Shape:** `(n_chunks, chunk_size)`
  - `n_chunks`: Number of chunks created from the data
  - `chunk_size`: Number of samples per chunk
- **Data Type:** `float64` for most signals
- **Compression:** gzip compression (default level 4) for reduced file size

**Common Signals:**
- `time`: Time values in seconds
- `abp`: Arterial Blood Pressure in mmHg
- `ecg`: Electrocardiogram (if available in original data)
- Additional signals depend on the original waveform file

**Example:**
```
signals/abp: shape (238, 250), dtype float64
  - 238 chunks
  - 250 samples per chunk
  - At 125 Hz: each chunk is 2 seconds
```

### `/labels/` Group

Contains chunk-level labels for classification or segmentation tasks.

**Dataset Structure:**
- **Shape:** `(n_chunks,)` - One label per chunk
- **Data Type:** `int32`
- **Compression:** gzip compression (default level 4)

**Available Labels:**

1. **`cpr_label`**: Indicates whether each chunk is from CPR or non-CPR periods
   - `0`: Non-CPR (data from before CPR start or after CPR stop)
   - `1`: CPR (data from during CPR, between cpr_start and cpr_stop)
   - Shape: `(n_chunks,)`

**Example:**
```python
# cpr_label array for a file with 10 CPR chunks followed by 5 non-CPR chunks:
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]
```

**Note:** CPR chunks are stored first in the file, followed by non-CPR chunks. Use the `time` signal to reorder chunks chronologically if needed.

### `/annotations/` Group

Contains review annotations indicating special events or data quality issues. These are time ranges from the original recording (in seconds).

**Dataset Structure:**
- **Shape:** `(n_events, 2)`
  - `n_events`: Number of annotated events
  - Column 0: Start time (seconds)
  - Column 1: Stop time (seconds)
- **Data Type:** `float64`

**Annotation Types:**

1. **`pause_times`**: Periods marked as "Pause"
   - Times when CPR was paused or interrupted
   - Shape: `(n_pause, 2)`

2. **`rosc_times`**: Periods marked as "Any ROSC" (Return of Spontaneous Circulation)
   - Times when patient showed signs of ROSC
   - Shape: `(n_rosc, 2)`

3. **`bad_data_times`**: Periods marked as "Bad Data"
   - Times with data quality issues (artifacts, missing data, etc.)
   - These regions are typically excluded from the chunked signals
   - Shape: `(n_bad, 2)`

**Example:**
```python
# pause_times array:
[[10.5, 15.2],    # Pause from 10.5s to 15.2s
 [45.0, 48.3]]    # Pause from 45.0s to 48.3s
```

**Note:** If no events of a particular type exist, the array will be empty with shape `(0, 2)`.

### `/metadata/` Group

Contains processing parameters and patient information.

**Standard Metadata Fields:**

1. **`patient_id`** (string): Patient identifier
   - Example: `"1071"`, `"10"`

2. **`chunk_size`** (int): Number of samples per chunk
   - Example: `250` (for 2-second chunks at 125 Hz)

3. **`skip_size`** (int): Number of samples to skip between chunk starts
   - Example: `125` (for 50% overlap with chunk_size=250)
   - If `skip_size < chunk_size`: chunks overlap
   - If `skip_size == chunk_size`: no overlap
   - If `skip_size > chunk_size`: gaps between chunks

4. **`sampling_rate`** (float): Actual sampling frequency in Hz
   - Example: `125.0` Hz

5. **`drop_incomplete`** (bool): Whether incomplete final chunks were dropped
   - `True`: Last chunk dropped if smaller than chunk_size
   - `False`: Last chunk padded with NaN values

**Optional Metadata:**
- Any additional parameters passed via `chunk_params` dictionary
- Example: `target_fs` (target sampling frequency before resampling)

## Data Processing Pipeline

The data in these HDF5 files has undergone the following processing steps:

1. **Resampling**: Original waveform data resampled to target frequency
   - Handles NaN values (removal or interpolation)
   - Creates uniform time vector

2. **Quality Labeling**: Each sample labeled based on review annotations
   - Label 0: Good Data
   - Label 1: Bad Data
   - Label 2: Pause
   - Label 3: Any ROSC

3. **Masking**: Bad data removed (typically keeping only Label 0)
   - Creates continuous segments of good quality data

4. **CPR Separation**: Data separated into CPR and non-CPR segments
   - Uses `cpr_start` and `cpr_stop` from review metadata
   - During-CPR: samples between cpr_start and cpr_stop
   - Not-during-CPR: samples before cpr_start or after cpr_stop

5. **Skip Size Calculation**: Calculate evenly-spaced block extraction
   - Target number of blocks (default: 10 per segment)
   - Adjusts if insufficient data available
   - Computes skip size to distribute blocks evenly

6. **Chunking**: Data split into fixed-size chunks
   - Configurable chunk size (default: 10 seconds)
   - Uses calculated skip size for even distribution
   - Sliding window approach

7. **CPR Labeling**: Each chunk labeled by CPR status
   - Label 0: Non-CPR chunk
   - Label 1: CPR chunk

8. **Combining**: CPR and non-CPR chunks combined
   - CPR chunks stored first, then non-CPR chunks
   - Original time vectors preserved for reordering

## Usage Examples

### Python (h5py)

```python
import h5py
import numpy as np

# Read the HDF5 file
with h5py.File('patient_1071_chunked.h5', 'r') as f:
    # Load signal data
    abp_chunks = f['signals/abp'][:]       # Shape: (n_chunks, chunk_size)
    time_chunks = f['signals/time'][:]     # Shape: (n_chunks, chunk_size)

    # Load CPR labels
    cpr_labels = f['labels/cpr_label'][:]  # Shape: (n_chunks,)

    # Load annotations
    pause_times = f['annotations/pause_times'][:]   # Shape: (n_pause, 2)
    rosc_times = f['annotations/rosc_times'][:]     # Shape: (n_rosc, 2)

    # Load metadata
    patient_id = f['metadata/patient_id'][()].decode('utf-8')
    chunk_size = f['metadata/chunk_size'][()]
    sampling_rate = f['metadata/sampling_rate'][()]

    print(f"Patient: {patient_id}")
    print(f"Total chunks: {abp_chunks.shape[0]}")
    print(f"CPR chunks: {np.sum(cpr_labels == 1)}")
    print(f"Non-CPR chunks: {np.sum(cpr_labels == 0)}")
    print(f"Samples per chunk: {chunk_size}")
    print(f"Sampling rate: {sampling_rate} Hz")

    # Separate CPR and non-CPR data
    cpr_abp = abp_chunks[cpr_labels == 1]
    non_cpr_abp = abp_chunks[cpr_labels == 0]
```

### Python (Lazy Loading)

```python
import h5py

# Open file without loading into memory
f = h5py.File('patient_1071_chunked.h5', 'r')

# Access specific chunks on demand
chunk_10 = f['signals/abp'][10, :]  # Load only chunk 10
chunks_0_to_50 = f['signals/abp'][0:50, :]  # Load first 50 chunks

# Calculate statistics without loading all data
mean_per_chunk = np.mean(f['signals/abp'][:], axis=1)

# Don't forget to close the file
f.close()
```

### MATLAB

```matlab
% Read the HDF5 file
filename = 'patient_1071_chunked.h5';

% Load signal data
abp_chunks = h5read(filename, '/signals/abp');  % Size: [chunk_size, n_chunks]
time_chunks = h5read(filename, '/signals/time');

% Note: MATLAB transposes arrays, so dimensions are reversed
% Transpose to match Python format: (n_chunks, chunk_size)
abp_chunks = abp_chunks';
time_chunks = time_chunks';

% Load CPR labels
cpr_labels = h5read(filename, '/labels/cpr_label');  % Size: [n_chunks, 1]

% Load annotations
pause_times = h5read(filename, '/annotations/pause_times');

% Load metadata
patient_id = h5read(filename, '/metadata/patient_id');
chunk_size = h5read(filename, '/metadata/chunk_size');
sampling_rate = h5read(filename, '/metadata/sampling_rate');

fprintf('Patient: %s\n', patient_id);
fprintf('Total chunks: %d\n', size(abp_chunks, 1));
fprintf('CPR chunks: %d\n', sum(cpr_labels == 1));
fprintf('Non-CPR chunks: %d\n', sum(cpr_labels == 0));
fprintf('Samples per chunk: %d\n', chunk_size);
fprintf('Sampling rate: %.1f Hz\n', sampling_rate);

% Separate CPR and non-CPR data
cpr_abp = abp_chunks(cpr_labels == 1, :);
non_cpr_abp = abp_chunks(cpr_labels == 0, :);
```

### Viewing File Structure (HDFView)

You can use [HDFView](https://www.hdfgroup.org/downloads/hdfview/) (free GUI tool) to inspect HDF5 files visually:
1. Download and install HDFView
2. Open the `.h5` file
3. Browse groups and datasets
4. View data values and attributes

## Interpreting Annotations

The annotation times indicate events in the **original** recording timeline, not the chunked data indices.

**Example Scenario:**
```
Original recording: 0 to 245 seconds
Bad data removed: ~825 samples (6.6 seconds at 125 Hz)
Chunked data: 238 chunks of 250 samples each

Annotations:
- pause_times: [[130.5, 135.2]]  # Pause from 130.5s to 135.2s
- rosc_times: [[200.0, 210.5]]   # ROSC from 200.0s to 210.5s
```

**Important Notes:**
1. Annotation times are in the **original time domain**
2. The chunked signals may not include these time ranges if they were masked out
3. Use annotations for context and event detection, not direct indexing into chunks

## File Size and Compression

**Typical File Sizes:**
- Uncompressed: ~20-50 MB per patient (depending on recording length)
- With gzip compression (level 4): ~5-15 MB per patient
- Compression ratio: typically 2-5x reduction

**Compression Settings:**
- **Algorithm:** gzip (portable across platforms)
- **Level:** 0-9 (default: 4)
  - 0: No compression (fastest)
  - 1: Fast compression, lower ratio
  - 4: Balanced (default)
  - 9: Maximum compression, slowest

## Compatibility

The HDF5 format is compatible with:
- Python: `h5py`, `tables` (PyTables)
- MATLAB: Built-in `h5read`, `h5write`
- R: `rhdf5` package
- Julia: `HDF5.jl` package
- C/C++: HDF5 C library
- Java: HDF5 Java library

## Version History

- **Version 1.1** (2026-01-16): Added CPR labels support
  - New `/labels/` group for chunk-level labels
  - Added `cpr_label` dataset (0=non-CPR, 1=CPR)
  - Updated pipeline to separate CPR and non-CPR data
  - CPR chunks stored first, then non-CPR chunks
  - Original time vectors preserved for chronological reordering

- **Version 1.0** (2026-01-13): Initial format specification
  - Three-group structure: signals, annotations, metadata
  - Support for multiple signal types
  - Pause, ROSC, and Bad Data annotations
  - Configurable compression

## Contact & Support

For questions or issues with the HDF5 format, refer to:
- `segment_waveform_data.py` - Source code and function documentation
- `cleaning_pipeline.ipynb` - Usage examples and demonstrations
